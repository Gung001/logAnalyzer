# thriftserver/beeline的使用
    1) 启动thriftserver: 默认端口是10000 ，可以修改
    2）启动beeline
    beeline -u jdbc:hive2://localhost:10000 -n hadoop


# thriftserver和普通的spark-shell/spark-sql有什么区别？
1）spark-shell、spark-sql都是一个spark  application；
2）thriftserver， 不管你启动多少个客户端(beeline/code)，永远都是一个spark application
	解决了一个数据共享的问题，多个客户端可以共享数据；

# 项目本地安装到maven仓库
mvn install:install-file -Dfile=D://resources//repository//com/ggstar//ipdatabase//1.0-SNAPSHOT//ipdatabase-1.0-SNAPSHOT.jar -DgroupId=com.ggstar -DartifactId=ipdatabase -Dversion=1.0 -Dpackaging=jar


# 项目打包命令
先加入一下插件--》依赖包
<plugin>
    <artifactId>maven-assembly-plugin</artifactId>
    <configuration>
        <archive>
            <manifest>
                <mainClass></mainClass>
            </manifest>
        </archive>
        <descriptorRefs>
            <descriptorRef>jar-with-dependencies</descriptorRef>
        </descriptorRefs>
    </configuration>
</plugin>

mvn assembly:assembly


# 作业提交到yarn上运行
spark-submit \
--class com.lxgy.log.StatCleanJobYarn \
--name StatCleanJobYarn \
--master yarn \
--executor-memory 1G \
--num-executors 1 \
/opt/datas/spark2.0/logAnalyzer-1.0-SNAPSHOT-jar-with-dependencies.jar \
hdfs://data01:8020/spark/data/access.log hdfs://data01:8020/spark/data/output/access_clean1


# 清洗作业提交到yarn上运行（需要依赖第三方文件）
spark-submit \
--class com.lxgy.log.StatCleanJobYarn \
--name StatCleanJobYarn \
--master yarn \
--executor-memory 1G \
--num-executors 1 \
--files /opt/datas/spark2.0/ipDatabase.csv,/opt/datas/spark2.0/ipRegion.xlsx \
/opt/datas/spark2.0/logAnalyzer-1.0-SNAPSHOT-jar-with-dependencies.jar \
hdfs://data01:8020/spark/data/access.log hdfs://data01:8020/spark/data/output/access_clean2


# 统计作业提交到yarn上运行
spark-submit \
--class com.lxgy.log.TopNStatJobYarn \
--name TopNStatJobYarn \
--master yarn \
--executor-memory 1G \
--num-executors 1 \
/opt/datas/spark2.0/logAnalyzer-1.0-SNAPSHOT-jar-with-dependencies.jar \
hdfs://data01:8020/spark/data/output/access_clean1 20170511






